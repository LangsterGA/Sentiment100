{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "marked-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#          Author:  Amy Louise Lang                                 #\n",
    "#            Date:  05/29/2021                                      #\n",
    "#     Data source:  https://www.kaggle.com/zusmani/trumps-legacy    #\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had problems importing the file so this code is a test to see my current working directory\n",
    "# In fact, it wasn't what I thought it was!\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"TrumpsLegcy.csv\", quotechar='\"', encoding ='utf-8',delimiter=',').dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm date format - not sure this is necessary\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want Trump's first 100 days of tweets - date ranges specified here\n",
    "start_date = '01-20-2017'\n",
    "end_date = '04-30-2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up filter statement\n",
    "filter100 = (df['date'] >= start_date) & (df['date'] <= end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[filter100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-hunger",
   "metadata": {},
   "source": [
    "# Data cleaning and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the id column since it is Donald Trump\n",
    "# However, since there are multiple ids, maybe I should count how many Twitter accounts are associated with Trump?\n",
    "# It would be interesting to compare that to Biden. It would show how many staff are participating in his messaging.\n",
    "df.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('text')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regular expressions to strip each tweet of mentions, hashtags, retweet information, and links\n",
    "def clean_tweet_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'RT[\\s]+', '', text)\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following line makes use of an apply function-- it will call clean_tweet_text on every element in the 'text' column\n",
    "df['text'].transform(clean_tweet_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-midwest",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which device is he tweeting from the most?\n",
    "df['device'].value_counts().head(n=5).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the top 10 most retweeted tweets?\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "df.sort_values(by='retweets', ascending=False)[['text', 'date', 'favorites', 'retweets']].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the top 10 favorited tweets?\n",
    "df.sort_values(by=['date', 'favorites'], ascending=[True, False])[['text', 'date', 'favorites', 'retweets']].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-citizenship",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-bracelet",
   "metadata": {},
   "source": [
    "We will be using the TextBlob library to perform sentiment analysis on the tweets in our dataset. \n",
    "TextBlob provides a simple API for diving into common natural language processing (NLP) tasks such as \n",
    "part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment of top 5 retweets\n",
    "tweet = TextBlob(\"Peaceful protests are a hallmark of our democracy. Even if I don't always agree, I recognize the rights of people to express their views.\")\n",
    "print(tweet.sentiment)\n",
    "tweet = TextBlob(\"What an amazing comeback and win by the Patriots. Tom Brady, Bob Kraft and Coach B are total winners. Wow!\")\n",
    "print(tweet.sentiment)\n",
    "tweet = TextBlob(\"It all begins today! I will see you at 11:00 A.M. for the swearing-in. THE MOVEMENT CONTINUES - THE WORK BEGINS!\")\n",
    "print(tweet.sentiment)\n",
    "tweet = TextBlob(\"Terrible! Just found out that Obama had my \"\"wires tapped\"\" in Trump Tower just before the victory. Nothing found. This is McCarthyism!\")\n",
    "print(tweet.sentiment)\n",
    "tweet = TextBlob(\"January 20th 2017, will be remembered as the day the people became the rulers of this nation again.\")\n",
    "print(tweet.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the TextBlob API onto our data to perform sentiment analysis for each tweet\n",
    "df['polarity'] = df['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['subjectivity'] = df['text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of polarity analysis results\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "df['polarity'].hist()\n",
    "plt.xlabel('Polarity Score', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "fig.savefig(\"Trump_polarity_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of subjectivity analysis results\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "df['subjectivity'].hist()\n",
    "plt.xlabel('Subjectivity Score', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "fig.savefig(\"Trump_subjectivity_hist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-singles",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect the most negatively charged tweets\n",
    "df.sort_values(by='polarity', ascending=True)[['text', 'polarity', 'subjectivity']].reset_index(drop=True).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the most positively charged tweets\n",
    "df.sort_values(by='polarity', ascending=False)[['text', 'polarity', 'subjectivity']].reset_index(drop=True).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the most subjective tweets (NOTE: subjectivity scale ranges from 0 to 1)\n",
    "df.sort_values(by='subjectivity', ascending=True)[['text', 'polarity', 'subjectivity']].reset_index(drop=True).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the most objective tweets\n",
    "df.sort_values(by='subjectivity', ascending=False)[['text', 'polarity', 'subjectivity']].reset_index(drop=True).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at # of tweets per day for first 100\n",
    "timeline = df.groupby(['date']).count().reset_index()\n",
    "timeline['count'] = timeline['text']\n",
    "timeline = timeline[['date', 'count']]\n",
    "fig = px.bar(timeline, x='date', y='count', labels={'date': 'Date', 'count': 'Tweet Count'})\n",
    "\n",
    "fig.show()\n",
    "#fig.write_image(\"Trump_tweet_freq_.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-cosmetic",
   "metadata": {},
   "source": [
    "# Time series sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarity values ranging from -1 to 1 are used for sentiment analysis\n",
    "# We will categorize by grouping our data into 3 classes (negative, neutral, and positive) for vsiualization\n",
    "criteria = [df['polarity'].between(-1, -0.01), df['polarity'].between(-0.01, 0.01), df['polarity'].between(0.01, 1)]\n",
    "values = ['Negative', 'Neutral', 'Positive']\n",
    "df['sentiment'] = np.select(criteria, values, 0)\n",
    "\n",
    "# plot sentiment counts\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "df['sentiment'].value_counts().sort_index().plot.bar()\n",
    "plt.xlabel('Sentiment Label', fontsize=18)\n",
    "plt.ylabel('Tweet Count', fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"Trump_sentiment_value_counts\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = df.groupby(['date']).agg(np.nanmean).reset_index()\n",
    "timeline['count'] = df.groupby(['date']).count().reset_index()['retweets']\n",
    "timeline = timeline[['date', 'count', 'polarity', 'retweets', 'favorites', 'subjectivity']]\n",
    "timeline[\"polarity\"] = timeline[\"polarity\"].astype(float)\n",
    "timeline[\"subjectivity\"] = timeline[\"subjectivity\"].astype(float)\n",
    "timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline.sort_values(by='polarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polarity scores over first 100 days\n",
    "fig = px.bar(timeline, x='date', y='count', color='polarity')\n",
    "fig.show()\n",
    "fig.write_image(\"Trump_polarity_100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjectivity scores over first 100 days\n",
    "fig = px.bar(timeline, x='date', y='count', color='subjectivity')\n",
    "fig.show()\n",
    "fig.write_image(\"Trump_subjectivity_100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import wordninja\n",
    "from spellchecker import SpellChecker\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import math\n",
    "import random\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))  \n",
    "stop_words.add(\"amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = df\n",
    "words = ' '.join([word for word in tweet_df['text']])\n",
    "word_cloud = WordCloud(width=1000, height=500, random_state=20, max_font_size=120, background_color='white').generate(words)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "fig.savefig(\"Trump_cloud_100\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-hurricane",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
